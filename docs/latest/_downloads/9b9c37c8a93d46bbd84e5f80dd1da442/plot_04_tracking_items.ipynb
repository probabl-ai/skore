{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Tracking items using their history\n\nThis example illustrates how skore can be used to track some items using their history,\nfor example tracking some ML metrics over time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating and loading the skore project\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by creating a temporary directory to store our project such that we can\neasily clean it after executing this example. If you want to keep the project,\nyou have to skip this section.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tempfile\nfrom pathlib import Path\n\nimport skore\n\ntemp_dir = tempfile.TemporaryDirectory(prefix=\"skore_example_\")\ntemp_dir_path = Path(temp_dir.name)\n\nmy_project = skore.create(\"my_project.skore\", working_dir=temp_dir_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tracking an integer\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us store several integer values for a same item called ``my_int``, each storage\nbeing separated by 0.1 second:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nmy_project.put(\"my_int\", 4)\ntime.sleep(0.1)\nmy_project.put(\"my_int\", 9)\ntime.sleep(0.1)\nmy_project.put(\"my_int\", 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us retrieve the history of this item:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "item_histories = my_project.get_item_versions(\"my_int\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us print the first history (first iteration) of this item:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "item_history = item_histories[0]\nprint(item_history)\nprint(item_history.primitive)\nprint(item_history.created_at)\nprint(item_history.updated_at)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Same, but for the second iteration:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "item_history = item_histories[1]\nprint(item_history.primitive)\nprint(item_history.created_at)\nprint(item_history.updated_at)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us construct a dataframe with the values and last updated times:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\n\nlist_primitive, list_created_at, list_updated_at = zip(\n    *[(elem.primitive, elem.created_at, elem.updated_at) for elem in item_histories]\n)\n\ndf_track = pd.DataFrame(\n    {\n        \"primitive\": list_primitive,\n        \"created_at\": list_created_at,\n        \"updated_at\": list_updated_at,\n    }\n)\ndf_track.insert(0, \"iteration_number\", np.arange(len(df_track)))\ndf_track"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tracking the value of the item over time:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n\nfig = px.line(\n    df_track,\n    x=\"iteration_number\",\n    y=\"primitive\",\n    hover_data=df_track.columns,\n    markers=True,\n)\nfig.update_layout(xaxis_type=\"category\")\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, wo focused on `how` to use skore's tracking of history of items.\n`Why` track items? For example, we could track some machine learning\nscores over time to understand better which feature engineering works best.\nIn the following, we explore skore's :func:`skore.cross_validate` that natively\nincludes tracking.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tracking the results of several runs of :func:`skore.cross_validate`\n====================================================================\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the `example_cross_validate` example, we saw why and how to use our\n:func:`skore.cross_validate` function.\nNow, let us see how we can use the tracking of items with this function.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us run several cross-validations using several values of a hyperparameter:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\nfrom sklearn.linear_model import Lasso\nimport skore\n\ndiabetes = datasets.load_diabetes()\nX = diabetes.data[:150]\ny = diabetes.target[:150]\nlasso = Lasso()\n\nfor alpha in [0.5, 1, 2]:\n    cv_results = skore.cross_validate(\n        Lasso(alpha=alpha), X, y, cv=5, project=my_project\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare the metrics of each run of the cross-validation (on all splits):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig_plotly = my_project.get_item(\"cross_validation_aggregated\").plot\nfig_plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hence, we can observe that the first run, with ``alpha=0.5``, works better.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}