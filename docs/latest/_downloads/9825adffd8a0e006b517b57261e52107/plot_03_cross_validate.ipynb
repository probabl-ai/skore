{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Enhancing cross-validation\n\nThis example illustrates the motivation and the use of skore's\n:func:`skore.cross_validate` to get assistance when developing your\nML/DS projects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating and loading the skore project\n\nWe start by creating a temporary directory to store our project such that we can\neasily clean it after executing this example. If you want to keep the project,\nyou have to skip this section.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tempfile\nfrom pathlib import Path\n\ntemp_dir = tempfile.TemporaryDirectory(prefix=\"skore_example_\")\ntemp_dir_path = Path(temp_dir.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import subprocess\n\n# create the skore project\nsubprocess.run(\n    f\"python3 -m skore create my_project_cv --working-dir {temp_dir.name}\".split()\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import skore\n\nmy_project_gs = skore.load(temp_dir_path / \"my_project_cv.skore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross-validation in scikit-learn\n\nScikit-learn holds two functions for cross-validation:\n\n* :func:`sklearn.model_selection.cross_val_score`\n* :func:`sklearn.model_selection.cross_validate`\n\nEssentially, :func:`sklearn.model_selection.cross_val_score` runs cross-validation for\nsingle metric evaluation, while :func:`sklearn.model_selection.cross_validate` runs\ncross-validation with multiple metrics and can also return extra information such as\ntrain scores, fit times, and score times.\n\nHence, in skore, we are more interested in the\n:func:`sklearn.model_selection.cross_validate` function as it allows to do\nmore than the historical :func:`sklearn.model_selection.cross_val_score`.\n\nLet us illustrate cross-validation on a multi-class classification task.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\nfrom sklearn.svm import SVC\n\nX, y = load_iris(return_X_y=True)\nclf = SVC(kernel=\"linear\", C=1, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Single metric evaluation using :func:`sklearn.model_selection.cross_validate`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate as sklearn_cross_validate\n\ncv_results = sklearn_cross_validate(clf, X, y, cv=5)\nprint(f\"test_score: {cv_results['test_score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multiple metric evaluation using :func:`sklearn.model_selection.cross_validate`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ncv_results = sklearn_cross_validate(\n    clf,\n    X,\n    y,\n    cv=5,\n    scoring=[\"accuracy\", \"precision_macro\"],\n)\ntest_scores = pd.DataFrame(cv_results)[[\"test_accuracy\", \"test_precision_macro\"]]\ntest_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### In scikit-learn, why do we recommend using ``cross_validate`` over ``cross_val_score``?\n\nHere, for the :class:`~sklearn.svm.SVC`, the default score is the accuracy.\nIf the users want other scores to better understand their model such as the\nprecision and the recall, they can specify it which is very convenient.\nOtherwise, they would have to run several\n:func:`sklearn.model_selection.cross_val_score` with different ``scoring``\nparameters each time, which leads to more unnecessary compute.\n\n### Why do we recommend using skore's ``cross_validate`` over scikit-learn's?\n\nIn the example above, what if the users ran scikit-learn's\n:func:`sklearn.model_selection.cross_validate` but forgot to manually add a\ncrucial score for their use case such as the recall?\nThey would have to re-run the whole cross-validation experiment by adding this\ncrucial score, which leads to more compute.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross-validation in skore\n\nIn order to assist its users when programming, skore has implemented a\n:func:`skore.cross_validate` function that wraps scikit-learn's\n:func:`sklearn.model_selection.cross_validate`, to provide more\ncontext and facilitate the analysis.\n\n### Classification task\n\nLet us continue with the same use case.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv_results = skore.cross_validate(clf, X, y, cv=5, project=my_project_gs)\n\nfig_plotly_clf = my_project_gs.get_item(\"cross_validation\").plot\nfig_plotly_clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Because Plotly graphs currently do not properly render in our Sphinx\n  auto-examples docs engine due to\n  [a bug in Plotly](https://github.com/plotly/plotly.py/issues/4828),\n  we also display its static image below.\n  Alternatively, we recommend zooming in / out in your browser window for the\n  Plotly graphs to display properly.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\nfig_plotly_clf.write_image(\"plot_03_cross_validate_clf.png\", scale=4)\n\nimg = mpimg.imread(\"plot_03_cross_validate_clf.png\")\nfig, ax = plt.subplots(layout=\"constrained\", dpi=200)\nax.axis(\"off\")\nax.imshow(img)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|\nSkore's :func:`~skore.cross_validate` advantages are the following:\n\n* By default, it computes several useful scores without the need for the user to\n  manually specify them. For classification, you can observe that it computed the\n  accuracy, the precision, and the recall.\n\n* You automatically get some interactive Plotly graphs to better understand how your\n  model behaves depending on the split. For example:\n\n  * You can compare the fitting and scoring times together for each split.\n\n  * You can compare the accuracy, precision, and recall scores together for each\n    split.\n\n* The results and plots are automatically saved in your skore project, so that you can\n  visualize them later in the UI for example.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regression task\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For now, all cross-validation runs store their results in the same place, which might\nlead to comparing two different models that are actually not comparable (e.g.\ncomparing a regression with a classification).\nTo remedy this, we clear the cross-validation information stored in skore before\nrunning another unrelated cross-validation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_project_gs.delete_item(\"cross_validation\")\nmy_project_gs.delete_item(\"cross_validation_aggregated\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Soon, the storage of several unrelated cross-validation runs will be managed\n  automatically.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\nfrom sklearn.linear_model import Lasso\n\ndiabetes = load_diabetes()\nX = diabetes.data[:150]\ny = diabetes.target[:150]\nlasso = Lasso()\n\ncv_results = skore.cross_validate(lasso, X, y, cv=5, project=my_project_gs)\n\nfig_plotly_reg = my_project_gs.get_item(\"cross_validation\").plot\nfig_plotly_reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cleanup the project\n\nRemove the temporary directory:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "temp_dir.cleanup()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}